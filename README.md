# HARDF: Partitioned Spatio-Temporal Attention for Depression Recognition

## Introduction
**HARDF** (Hybrid Attention for Regional Dynamic Facial features) is a novel deep learning framework designed for **Automatic Depression Estimation (ADE)** based on facial video analysis.  
The key innovation lies in the **Fusion of Spatio-Temporal Attention (FSTA)** module, which partitions facial images into multiple subregions and adaptively integrates:
- **Spatial importance**  
- **Spatial contextual relationships**  
- **Temporal contextual relationships**  
- **Regional similarity**  

This design allows HARDF to capture **fine-grained facial dynamics** and **subtle temporal variations** closely associated with depression severity.  
Experiments on the **AVEC2013** and **AVEC2014** datasets demonstrate that HARDF achieves **state-of-the-art performance** in terms of both MAE and RMSE.

---

## Code Availability
We have made the core **HARDF source code** publicly available to facilitate research reproducibility and future development:  
[**GitHub Repository: HARDF**](https://github.com/muzixingyun/HARDF)

---

## Training & Usage
We are currently organizing and cleaning up the **training scripts**, **configuration files**, and **detailed usage instructions**.  
The following resources will be released in the upcoming update:
- End-to-end training scripts for HARDF
- Hyperparameter settings and training protocols
- Evaluation scripts for AVEC2013 and AVEC2014 datasets

Please stay tuned for the next release!

---
